{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b393e3-9df6-4a97-9b6c-e1acb4476ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import ray\n",
    "from ray.util.sgd.torch import TrainingOperator\n",
    "from ray.util.sgd.torch.examples.train_example import LinearDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc94e471-877b-4708-8509-faf790d6b906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Ray cluster...\n"
     ]
    }
   ],
   "source": [
    "if ray.is_initialized() == False:\n",
    "        print(\"Connecting to Ray cluster...\")\n",
    "        service_host = os.environ[\"RAY_HEAD_SERVICE_HOST\"]\n",
    "        service_port = os.environ[\"RAY_HEAD_SERVICE_PORT\"]\n",
    "        ray.util.connect(f\"{service_host}:{service_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84d314a7-f278-4fbb-9b42-0379b1ea7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainingOperator(TrainingOperator):\n",
    "    def setup(self, config):\n",
    "        # Setup all components needed for training here. This could include\n",
    "        # data, models, optimizers, loss & schedulers.\n",
    "\n",
    "        # Setup data loaders.\n",
    "        train_dataset, val_dataset = LinearDataset(2, 5), LinearDataset(2,\n",
    "                                                                        5)\n",
    "        train_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=config[\"batch_size\"])\n",
    "        val_loader = DataLoader(val_dataset,\n",
    "                                batch_size=config[\"batch_size\"])\n",
    "\n",
    "        # Setup model.\n",
    "        model = nn.Linear(1, 1)\n",
    "\n",
    "        # Setup optimizer.\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config.get(\"lr\", 1e-4))\n",
    "\n",
    "        # Setup loss.\n",
    "        criterion = torch.nn.BCELoss()\n",
    "\n",
    "        # Setup scheduler.\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "\n",
    "        # Register all of these components with Ray SGD.\n",
    "        # This allows Ray SGD to do framework level setup like Cuda, DDP,\n",
    "        # Distributed Sampling, FP16.\n",
    "        # We also assign the return values of self.register to instance\n",
    "        # attributes so we can access it in our custom training/validation\n",
    "        # methods.\n",
    "        self.model, self.optimizer, self.criterion, self.scheduler = \\\n",
    "            self.register(models=model, optimizers=optimizer,\n",
    "                          criterion=criterion,\n",
    "                          schedulers=scheduler)\n",
    "        self.register_data(train_loader=train_loader, validation_loader=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "031e37a2-ad3c-4f77-9f4e-c583c414f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.util.sgd import TorchTrainer\n",
    "\n",
    "trainer = TorchTrainer(\n",
    "    training_operator_cls=MyTrainingOperator,\n",
    "    scheduler_step_freq=\"epoch\",  # if scheduler is used\n",
    "    config={\"lr\": 0.001, \"batch_size\": 64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9116e369-daf1-4b06-8612-dab38dc46212",
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(RuntimeError)",
     "evalue": "\u001b[36mray::TorchRunner.train_epoch()\u001b[39m (pid=46, ip=100.96.3.66)\n  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/torch_runner.py\", line 140, in train_epoch\n    train_stats = self.training_operator.train_epoch(iterator, info)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 510, in train_epoch\n    metrics = self.train_batch(batch, batch_info=batch_info)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 588, in train_batch\n    loss = criterion(output, target)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\", line 516, in forward\n    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\", line 2378, in binary_cross_entropy\n    return torch._C._nn.binary_cross_entropy(\nRuntimeError: all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(RuntimeError)\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/torch/torch_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_steps, profile, reduce_results, max_retries, info, dataset)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resize opportunity detected. Attempting to scale up.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resize_worker_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         success, worker_stats = self.worker_group.train(\n\u001b[0m\u001b[1;32m    424\u001b[0m             num_steps=num_steps, profile=profile, info=info, dataset=dataset)\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# Fault handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/torch/worker_group.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_steps, profile, info, dataset)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mremote_worker_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# Check if each worker has failed before calling ray.get.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_for_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_worker_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_worker_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/utils.py\u001b[0m in \u001b[0;36mcheck_for_failure\u001b[0;34m(remote_values)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfinished\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mfinished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfinished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRayActorError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmilliseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                         \u001b[0mop_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_BLOCKING_OPERATION_TIME_S\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mGetTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/worker.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, ref, timeout)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to deserialize {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloads_from_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(RuntimeError)\u001b[0m: \u001b[36mray::TorchRunner.train_epoch()\u001b[39m (pid=46, ip=100.96.3.66)\n  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/torch_runner.py\", line 140, in train_epoch\n    train_stats = self.training_operator.train_epoch(iterator, info)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 510, in train_epoch\n    metrics = self.train_batch(batch, batch_info=batch_info)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 588, in train_batch\n    loss = criterion(output, target)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\", line 516, in forward\n    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\", line 2378, in binary_cross_entropy\n    return torch._C._nn.binary_cross_entropy(\nRuntimeError: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d395138-5de1-4974-8e51-8f2100c64b09",
   "metadata": {},
   "outputs": [
    {
     "ename": "RayTaskError(RuntimeError)",
     "evalue": "\u001b[36mray::TorchRunner.train_epoch()\u001b[39m (pid=345, ip=100.96.3.67)\n  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/torch_runner.py\", line 140, in train_epoch\n    train_stats = self.training_operator.train_epoch(iterator, info)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 510, in train_epoch\n    metrics = self.train_batch(batch, batch_info=batch_info)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 588, in train_batch\n    loss = criterion(output, target)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\", line 516, in forward\n    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\", line 2378, in binary_cross_entropy\n    return torch._C._nn.binary_cross_entropy(\nRuntimeError: all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRayTaskError(RuntimeError)\u001b[0m                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3ee4a1380e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mval_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/torch/torch_trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_steps, profile, reduce_results, max_retries, info, dataset)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resize opportunity detected. Attempting to scale up.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resize_worker_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         success, worker_stats = self.worker_group.train(\n\u001b[0m\u001b[1;32m    424\u001b[0m             num_steps=num_steps, profile=profile, info=info, dataset=dataset)\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# Fault handling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/torch/worker_group.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_steps, profile, info, dataset)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mremote_worker_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# Check if each worker has failed before calling ray.get.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_for_failure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_worker_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_worker_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/sgd/utils.py\u001b[0m in \u001b[0;36mcheck_for_failure\u001b[0;34m(remote_values)\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfinished\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0mfinished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfinished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0mfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRayActorError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclient_mode_should_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmilliseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, vals, timeout)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                         \u001b[0mop_timeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMAX_BLOCKING_OPERATION_TIME_S\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mGetTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/util/client/worker.py\u001b[0m in \u001b[0;36m_get\u001b[0;34m(self, ref, timeout)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to deserialize {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloads_from_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRayTaskError(RuntimeError)\u001b[0m: \u001b[36mray::TorchRunner.train_epoch()\u001b[39m (pid=345, ip=100.96.3.67)\n  File \"python/ray/_raylet.pyx\", line 505, in ray._raylet.execute_task\n  File \"python/ray/_raylet.pyx\", line 449, in ray._raylet.execute_task.function_executor\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/_private/function_manager.py\", line 556, in actor_method_executor\n    return method(__ray_actor, *args, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/torch_runner.py\", line 140, in train_epoch\n    train_stats = self.training_operator.train_epoch(iterator, info)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 510, in train_epoch\n    metrics = self.train_batch(batch, batch_info=batch_info)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/ray/util/sgd/torch/training_operator.py\", line 588, in train_batch\n    loss = criterion(output, target)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 550, in __call__\n    result = self.forward(*input, **kwargs)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\", line 516, in forward\n    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n  File \"/home/ray/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\", line 2378, in binary_cross_entropy\n    return torch._C._nn.binary_cross_entropy(\nRuntimeError: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    metrics = trainer.train()\n",
    "    val_metrics = trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c99d6d74-ffad-4a86-96c6-f552e193706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.util.sgd.torch import TorchTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7850405c-653f-4481-8e95-d02e68011b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TorchTrainer in module ray.util.sgd.torch.torch_trainer:\n",
      "\n",
      "class TorchTrainer(builtins.object)\n",
      " |  TorchTrainer(*, training_operator_cls, initialization_hook=None, config=None, num_workers=1, num_cpus_per_worker=1, use_gpu='auto', backend='auto', wrap_ddp=True, timeout_s=1800, use_fp16=False, use_tqdm=False, add_dist_sampler=True, scheduler_step_freq=None, use_local=False, num_replicas=None, batch_size=None, model_creator=None, data_creator=None, optimizer_creator=None, scheduler_creator=None, loss_creator=None, serialize_data_creation=None, data_loader_args=None, apex_args=None)\n",
      " |  \n",
      " |  Train a PyTorch model using distributed PyTorch.\n",
      " |  \n",
      " |  Launches a set of actors which connect via distributed PyTorch and\n",
      " |  coordinate gradient updates to train the provided model. If Ray is not\n",
      " |  initialized, TorchTrainer will automatically initialize a local Ray\n",
      " |  cluster for you. Be sure to run `ray.init(address=\"auto\")` to leverage\n",
      " |  multi-node training.\n",
      " |  \n",
      " |  .. code-block:: python\n",
      " |  \n",
      " |      class MyTrainingOperator(TrainingOperator):\n",
      " |  \n",
      " |          def setup(self, config):\n",
      " |              model = nn.Linear(1, 1)\n",
      " |              optimizer = torch.optim.SGD(\n",
      " |                  model.parameters(), lr=config.get(\"lr\", 1e-4))\n",
      " |              loss = torch.nn.MSELoss()\n",
      " |  \n",
      " |              batch_size = config[\"batch_size\"]\n",
      " |              train_data, val_data = LinearDataset(2, 5), LinearDataset(2, 5)\n",
      " |              train_loader = DataLoader(train_data, batch_size=batch_size)\n",
      " |              val_loader = DataLoader(val_data, batch_size=batch_size)\n",
      " |  \n",
      " |              self.model, self.optimizer = self.register(\n",
      " |                  models=model,\n",
      " |                  optimizers=optimizer,\n",
      " |                  criterion=loss)\n",
      " |  \n",
      " |              self.register_data(\n",
      " |                  train_loader=train_loader,\n",
      " |                  validation_loader=val_loader)\n",
      " |  \n",
      " |  \n",
      " |      trainer = TorchTrainer(\n",
      " |          training_operator_cls=MyTrainingOperator,\n",
      " |          config={\"batch_size\": 32},\n",
      " |          use_gpu=True\n",
      " |      )\n",
      " |      for i in range(4):\n",
      " |          trainer.train()\n",
      " |  \n",
      " |  Args:\n",
      " |      training_operator_cls (type): Custom training operator class\n",
      " |          that subclasses the TrainingOperator class. This class\n",
      " |          will be copied onto all remote workers and used to specify\n",
      " |          training components and custom training and validation operations.\n",
      " |      initialization_hook (function): A function to call on all training\n",
      " |          workers when they are first initialized. This could be useful to\n",
      " |          set environment variables for all the worker processes.\n",
      " |      config (dict): Custom configuration value to be passed to\n",
      " |          all operator constructors.\n",
      " |      num_workers (int): the number of workers used in distributed\n",
      " |          training. If 1, the worker will not be wrapped with\n",
      " |          DistributedDataParallel. TorchTrainer will scale down the number\n",
      " |          of workers if enough resources are not available, and will scale\n",
      " |          back up once they are. The total number of\n",
      " |          workers will never exceed `num_workers` amount.\n",
      " |      num_cpus_per_worker (int): Sets the cpu requirement for each worker.\n",
      " |      use_gpu (bool): Sets resource allocation for workers to 1 GPU\n",
      " |          if true, and automatically moves both the model and optimizer\n",
      " |          to the available CUDA device.\n",
      " |      backend (string): backend used by distributed PyTorch. Currently\n",
      " |          support \"nccl\", \"gloo\", and \"auto\". If \"auto\", RaySGD will\n",
      " |          automatically use \"nccl\" if `use_gpu` is True, and \"gloo\"\n",
      " |          otherwise.\n",
      " |      wrap_ddp (bool): Whether to automatically wrap DistributedDataParallel\n",
      " |          over each model. If False, you are expected to call it yourself.\n",
      " |      timeout_s (float): Seconds before the torch process group\n",
      " |          times out. Useful when machines are unreliable. If not set, default\n",
      " |          to 30 min, which is the same default as\n",
      " |          ``torch.init_process_group(...)``.\n",
      " |      add_dist_sampler (bool): Whether to automatically add a\n",
      " |          DistributedSampler to all created dataloaders. Only applicable\n",
      " |          if num_workers > 1.\n",
      " |      use_fp16 (bool): Enables mixed precision training via apex if apex\n",
      " |          is installed. This is automatically done after the model and\n",
      " |          optimizers are constructed and will work for multi-model training.\n",
      " |          Please see https://github.com/NVIDIA/apex for more details.\n",
      " |      scheduler_step_freq: \"batch\", \"epoch\", \"manual\", or None. This will\n",
      " |          determine when ``scheduler.step`` is called. If \"batch\",\n",
      " |          ``step`` will be called after every optimizer step. If \"epoch\",\n",
      " |          ``step`` will be called after one pass of the DataLoader. If\n",
      " |          \"manual\", the scheduler will not be incremented automatically -\n",
      " |          you are expected to call ``trainer.update_scheduler`` manually.\n",
      " |          If a scheduler is passed in, this value is expected to not be None.\n",
      " |      use_local (bool): If True, 1 worker will be a local worker running\n",
      " |          on the driver process, and all other workers will be remote. If\n",
      " |          False, all workers will be remote. Set this to True for easy\n",
      " |          debugging of worker on driver process, but could also\n",
      " |          lead to issues with Cuda devices. Defaults to False.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, training_operator_cls, initialization_hook=None, config=None, num_workers=1, num_cpus_per_worker=1, use_gpu='auto', backend='auto', wrap_ddp=True, timeout_s=1800, use_fp16=False, use_tqdm=False, add_dist_sampler=True, scheduler_step_freq=None, use_local=False, num_replicas=None, batch_size=None, model_creator=None, data_creator=None, optimizer_creator=None, scheduler_creator=None, loss_creator=None, serialize_data_creation=None, data_loader_args=None, apex_args=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  apply_all_operators(self, fn)\n",
      " |      Run a function on all operators on the workers.\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (Callable[TrainingOperator]): A function that takes in a\n",
      " |              TrainingOperator.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of objects returned by ``fn`` on each operator.\n",
      " |  \n",
      " |  apply_all_workers(self, fn)\n",
      " |      Run a function on all operators on the workers.\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (Callable): A function that takes in no arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of objects returned by ``fn`` on each worker.\n",
      " |  \n",
      " |  get_local_operator(self)\n",
      " |      Returns the local TrainingOperator object.\n",
      " |      \n",
      " |      Be careful not to perturb its state, or else you can cause the system\n",
      " |      to enter an inconsistent state.\n",
      " |      \n",
      " |      Returns:\n",
      " |          TrainingOperator: The local TrainingOperator object.\n",
      " |  \n",
      " |  get_model(self)\n",
      " |      Returns the learned model(s).\n",
      " |  \n",
      " |  load(self, checkpoint)\n",
      " |      Loads the Trainer and all workers from the provided checkpoint.\n",
      " |      \n",
      " |      Args:\n",
      " |          checkpoint (str): Path to target checkpoint file.\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, blocking=False)\n",
      " |  \n",
      " |  restore(self, *args)\n",
      " |  \n",
      " |  save(self, checkpoint)\n",
      " |      Saves the Trainer state to the provided checkpoint path.\n",
      " |      \n",
      " |      Args:\n",
      " |          checkpoint (str): Path to target checkpoint file.\n",
      " |  \n",
      " |  shutdown(self, force=False)\n",
      " |      Shuts down workers and releases resources.\n",
      " |      \n",
      " |      Args:\n",
      " |          force (bool): If True, forcefully kill all workers. If False,\n",
      " |              attempt a graceful shutdown first, and then forcefully kill if\n",
      " |              unsuccessful.\n",
      " |  \n",
      " |  state_dict(self)\n",
      " |  \n",
      " |  train(self, num_steps=None, profile=False, reduce_results=True, max_retries=3, info=None, dataset=None)\n",
      " |      Runs a training epoch.\n",
      " |      \n",
      " |      Calls `operator.train_epoch()` on N parallel workers simultaneously\n",
      " |      underneath the hood.\n",
      " |      \n",
      " |      Set `max_retries` to enable fault handling in case of\n",
      " |      instance preemption.\n",
      " |      \n",
      " |      Args:\n",
      " |          num_steps (int): Number of batches to compute update steps on\n",
      " |              per worker. This corresponds also to the number of times\n",
      " |              ``TrainingOperator.train_batch`` is called per worker.\n",
      " |          profile (bool): Returns time stats for the training procedure.\n",
      " |          reduce_results (bool): Whether to average all metrics across\n",
      " |              all workers into one dict. If a metric is a non-numerical\n",
      " |              value (or nested dictionaries), one value will be randomly\n",
      " |              selected among the workers. If False, returns a list of dicts.\n",
      " |          max_retries (int): Must be non-negative. If set to N, TorchTrainer\n",
      " |              will detect and recover from training failure. The recovery\n",
      " |              process will kill all current workers, query the Ray\n",
      " |              global state for total available resources, and re-launch up to\n",
      " |              the available resources. Behavior is not well-defined\n",
      " |              in case of shared cluster usage. Defaults to 3.\n",
      " |          info (dict): Optional dictionary passed to the training\n",
      " |              operator for ``train_epoch`` and ``train_batch``.\n",
      " |          dataset (Dataset): Optional dataset to train with. If specified,\n",
      " |              the dataloader passed in via data_creator will be ignored.\n",
      " |      \n",
      " |      Returns:\n",
      " |          (dict | list) A dictionary of metrics for training.\n",
      " |              You can provide custom metrics by implementing a custom\n",
      " |              training loop. If ``reduce_results=False``, this will return a\n",
      " |              list of metric dictionaries whose length will be equal to\n",
      " |              ``num_workers``.\n",
      " |  \n",
      " |  update_scheduler(self, metric)\n",
      " |      Calls ``scheduler.step(metric)`` on all registered schedulers.\n",
      " |      \n",
      " |      This is useful for lr_schedulers such as ``ReduceLROnPlateau``.\n",
      " |  \n",
      " |  validate(self, num_steps=None, profile=False, reduce_results=True, info=None)\n",
      " |      Evaluates the model on the validation data set.\n",
      " |      \n",
      " |      Args:\n",
      " |          num_steps (int): Number of batches to compute update steps on\n",
      " |              per worker. This corresponds also to the number of times\n",
      " |              ``TrainingOperator.validate_batch`` is called per worker.\n",
      " |          profile (bool): Returns time stats for the evaluation procedure.\n",
      " |          reduce_results (bool): Whether to average all metrics across\n",
      " |              all workers into one dict. If a metric is a non-numerical\n",
      " |              value (or nested dictionaries), one value will be randomly\n",
      " |              selected among the workers. If False, returns a list of dicts.\n",
      " |          info (dict): Optional dictionary passed to the training\n",
      " |              operator for `validate` and `validate_batch`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A dictionary of metrics for validation.\n",
      " |              You can provide custom metrics by passing in a custom\n",
      " |              ``training_operator_cls``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  as_trainable(*args, override_tune_step=None, **kwargs) from builtins.type\n",
      " |      Creates a BaseTorchTrainable class compatible with Tune.\n",
      " |      \n",
      " |      Any configuration parameters will be overridden by the Tune\n",
      " |      Trial configuration. You can also pass in a custom\n",
      " |      ``override_tune_step`` to implement your own iterative optimization\n",
      " |      routine and override the default implementation.\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          def step(trainer, info):\n",
      " |              # Implement custom objective function here.\n",
      " |              train_stats = trainer.train()\n",
      " |              ...\n",
      " |              # Return the metrics to report to tune.\n",
      " |              # Do not call tune.report here.\n",
      " |              return train_stats\n",
      " |      \n",
      " |          TorchTrainable = TorchTrainer.as_trainable(\n",
      " |              training_operator_cls=MyTrainingOperator,\n",
      " |              num_workers=2,\n",
      " |              use_gpu=True,\n",
      " |              override_tune_step=step\n",
      " |          )\n",
      " |          analysis = tune.run(\n",
      " |              TorchTrainable,\n",
      " |              config={\"lr\": tune.grid_search([0.01, 0.1])}\n",
      " |          )\n",
      " |      \n",
      " |      Args:\n",
      " |          override_tune_step (Callable[[TorchTrainer, Dict], Dict]): A\n",
      " |              function to override the default training step to be used\n",
      " |              for Ray Tune. It accepts two arguments: the first one is an\n",
      " |              instance of your TorchTrainer, and the second one is a info\n",
      " |              dictionary, containing information about the Trainer\n",
      " |              state. If None is passed in, the default step\n",
      " |              function will be\n",
      " |              used: run 1 epoch of training, 1 epoch of validation,\n",
      " |              and report both results to Tune. Passing in\n",
      " |              ``override_tune_step`` is useful to define\n",
      " |              custom step functions, for example if you need to\n",
      " |              manually update the scheduler or want to run more than 1\n",
      " |              training epoch for each tune iteration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TorchTrainer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
